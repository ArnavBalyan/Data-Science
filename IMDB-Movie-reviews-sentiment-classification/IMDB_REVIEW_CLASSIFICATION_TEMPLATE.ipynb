{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB-REVIEW-CLASSIFICATION-TEMPLATE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_aXRjz_gVUL",
        "colab_type": "text"
      },
      "source": [
        "## **IMDB-Movie-reviews-sentiment-classification**\n",
        "\n",
        "\n",
        "\n",
        "The data set contains 50,000 movie reviews from Internet Movie Database (IMDB) labeled whether they are positive or negative.\n",
        "\n",
        "**Task is to build a prediction model that will accurately classify which review are positive and negative**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FR3etX_5ga5U",
        "colab_type": "text"
      },
      "source": [
        "## **Steps:**\n",
        "- Importing Libraries\n",
        "- Uploading  dataset\n",
        "- Analyze dataset\n",
        "- Preprocessing data\n",
        " - Tokenize \n",
        " - Text to sequence\n",
        " - Padding or truncating \n",
        "- Building model\n",
        "- Training model and validating model\n",
        "- Predict a review from user\n",
        "- Conclusion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCUqcbQkgsKD",
        "colab_type": "text"
      },
      "source": [
        "## **Importing required Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7PvRm3vfuff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# These are the libraray which will be used in solution you can use any other libraries \n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBTH9PpTg-N5",
        "colab_type": "text"
      },
      "source": [
        "## **Uploading Dataset**\n",
        "\n",
        "IMDB dataset having 50K movie reviews for natural language processing or Text analytics.\n",
        "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training and 25,000 for testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_u7mtQ7g9XC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = #Upload data using pandas method"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLVUd_N-hOMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display the top 5 rows and column\n",
        "# Write your one line code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DqiEcwdhUBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Describe the data using describe method \n",
        "# Write your one line code here      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-nqF97ch1XY",
        "colab_type": "text"
      },
      "source": [
        "**Encode label of sentiment as 0 and 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J334o7Dhhbt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets encode labels: each label is an integer value of either 0 or 1, where 0 is a negative review, and 1 is a positive review.\n",
        "\n",
        "#Write your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg5yzYZyiCng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check the top rows and column that the changes are made in sentiment column or not"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4RXRVEDiLLo",
        "colab_type": "text"
      },
      "source": [
        "## **Analyze Data**\n",
        "\n",
        "- Make histogram by distribution through length of data\n",
        "- Make histogram by the frequency of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuhQ5k9HiONo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You can use any other method to plot graph if you want below is one of the method\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(# write your code here)\n",
        "plt.xlabel('Length of samples')\n",
        "plt.ylabel('Number of samples')\n",
        "plt.title('Sample length distribution')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN1kGij8jKjG",
        "colab_type": "text"
      },
      "source": [
        "Plot graph that will show the frequency of words occuring\n",
        "\n",
        "You can use CountVectorizer() method you can learn more about it by following link [Vectorizer](https://scikit-learn.org/stable/modules/feature_extraction.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl7qg00Jigg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c30rHTuj0a1",
        "colab_type": "text"
      },
      "source": [
        "## **Preprocessing Data**\n",
        "\n",
        "**Spliting data set as train and test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRfmjAKpj2LF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split data in train and test with 25000 in train and 25000 in test data\n",
        "\n",
        "X=data.review\n",
        "X=X.to_numpy()\n",
        "y = data.sentiment\n",
        "y=y.to_numpy()\n",
        "\n",
        "# Write your code here using train_test_split method with test size equal to 50 percent of total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xS5DPzwkI5M",
        "colab_type": "text"
      },
      "source": [
        "**Finding shape of train sentences and train labels using numpy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxAP18UlkKGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display the shape of training sentence and testing sentences\n",
        "print(#Write code here)\n",
        "print(#Write code here)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LAwpoTQkXsM",
        "colab_type": "text"
      },
      "source": [
        "**Defining variable**\n",
        "\n",
        "Vocab_size : Upper limit of diffrent words (  Note that the vocab_size is specified large enough so as to ensure unique integer encoding for each and every word.)\n",
        "\n",
        "max_length : What will be the maximum length of sentence\n",
        "\n",
        "trunc_type : If sentence exceed max_length then where to truncate a sentence from begining or at end using 'post and 'pre' methods\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3AFPYQqkZTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# these variable value can be changed you should change and see the diffrence in the model.\n",
        "vocab_size=10000 \n",
        "embedding_dim=16\n",
        "max_length=120\n",
        "trunc_type='post' # It can be changed to pre and then see the diffrence in accuracy\n",
        "oov_tok='<OOV>'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KHHx0HFkbtr",
        "colab_type": "text"
      },
      "source": [
        "**Tokenize sequence**\n",
        "\n",
        " Tokenization is the task of chopping it up into pieces, called tokens.\n",
        "\n",
        " Eg.\n",
        " Input - How are you\n",
        "\n",
        " Output - 'How', 'are', 'you' \n",
        "\n",
        " Here is a sample python code for better understanding\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        " sentences = [\n",
        "    'I love my dog',\n",
        "    'I love my cat so much',\n",
        "    'You love my dog!'\n",
        "]\n",
        "\n",
        "Create object of Tokenizer and tokenize sentences\n",
        "\n",
        "tokenizer = Tokenizer(num_words = 100)  # max distinct words first 100 words\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHfYXQrqkvqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = #Write your code here\n",
        "# Write code to fit on text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hrpzG8Zk8tr",
        "colab_type": "text"
      },
      "source": [
        "**Text to sequence**\n",
        "\n",
        "\n",
        "texts_to_sequences Transforms each text in texts to a sequence of integers. So it basically takes each word in the text and replaces it with its corresponding integer value from the word_index dictionary. Nothing more, nothing less, certainly no magic involved.\n",
        "\n",
        "Here two function will require text_to_sequences and word_index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANaXwl4ck-KD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index= # Write your code here\n",
        "sequences= # Write your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3fD9VTZlPNK",
        "colab_type": "text"
      },
      "source": [
        "**Padding sequence**\n",
        "\n",
        "The pad_sequences() function in the Keras deep learning library can be used to pad variable length sequences.\n",
        "\n",
        "The pad_sequences() function can also be used to pad sequences to a preferred length that may be longer than any observed sequences.\n",
        "\n",
        "This can be done by specifying the “maxlen” argument to the desired length. Padding will then be performed on all sequences to achieve the desired length, as follows.\n",
        "\n",
        "A sample python code is given below for better understanding.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "padded_sequences = pad_sequences(sequences, padding='post',truncating='post',maxlen=5)\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGP6y3TtlQy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "padded=# Write code to pad train sentences\n",
        "testing_sequences= # Write code to convert test sentences from text to sentence using text_to_sentence method\n",
        "testing_padded= # Write code to pad test sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfBvib9oloVa",
        "colab_type": "text"
      },
      "source": [
        "**Compairing padded sequence with normal sequence**\n",
        "\n",
        "Print padded sequence and normal sequence to see the diffrence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Mm8uuRCl22S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(# Write your code here)\n",
        "print(# Write  your code here)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdO-Zb0tmBR5",
        "colab_type": "text"
      },
      "source": [
        "**Integer value corresponding to words**\n",
        "\n",
        "In the below cell there is the list of diffrent words with their corresponding unique index value which we have created using text_to_sequences function in one of the above cell.\n",
        "\n",
        "It can be printed using word_index method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMFWRaYUmExp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR98JiZfmNTB",
        "colab_type": "text"
      },
      "source": [
        "##**Building Model**\n",
        "\n",
        "Here we have used LSTM algorithm\n",
        "\n",
        " ***What is LSTM ?***\n",
        "\n",
        "LSTM stands for long short term memory. It is a model or architecture that extends the memory of recurrent neural networks. Typically, recurrent neural networks have ‘short term memory’ in that they use persistent previous information to be used in the current neural network. Essentially, the previous information is used in the present task. That means we do not have a list of all of the previous information available for the neural node.\n",
        "\n",
        " ***How LSTM works ?***\n",
        "\n",
        "LSTM introduces long-term memory into recurrent neural networks. It mitigates the vanishing gradient problem, which is where the neural network stops learning because the updates to the various weights within a given neural network become smaller and smaller. It does this by using a series of ‘gates’. These are contained in memory blocks which are connected through layer.\n",
        "\n",
        "There are three types of gates within a unit:\n",
        "\n",
        "\n",
        "1.   Input Gate: Scales input to cell (write)\n",
        "2.   Output Gate: Scales output to cell (read)\n",
        "3.   Forget Gate: Scales old cell value (reset)      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "Each gate is like a switch that controls the read/write, thus incorporating the long-term memory function into the model.\n",
        "\n",
        "**No. of layers**\n",
        "\n",
        "Use 6 hidden layers and one output layer with hidden layer activation function as relu and output layer activation function as sigmoid.\n",
        "\n",
        "*Note : You can change the activation function and and number of layers we have taken one combination try diffrent and compare the accuracy.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igM1Va1nmQDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = tf.keras.Sequential([\n",
        "    # Write your code here to build LSTM model\n",
        "])\n",
        "\n",
        "# Write code here to compile the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI9dY6hcm59t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write code to get the summary of model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajgh-1ZsnAOY",
        "colab_type": "text"
      },
      "source": [
        "##**Training and validating model**\n",
        "\n",
        "1.   We have used 5 epochs to train\n",
        "2.   No of training data = No of validating data = 25000\n",
        "\n",
        " *Note - You can change the value of epoch*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAMKJGoVnPMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = # Define epoch value\n",
        "# Write your code here to fit model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyT-dgbGndzP",
        "colab_type": "text"
      },
      "source": [
        "##**Predict a review from user**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmsPMND6njhm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = \"boring\"\n",
        "sequence = # Write code for converting into sequence\n",
        "\n",
        "sequence= # Write code to pad it\n",
        "\n",
        "k=# Write a code to predict using the model you have build\n",
        "if k==0:\n",
        "   print(\"Negative Review\")\n",
        "else:\n",
        "   print(\"Positive review\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UL570NtoJrM",
        "colab_type": "text"
      },
      "source": [
        "##**Conclusion**\n",
        "\n",
        "We have implemented LSTM RNN model in our dataet after preprocessing the dataset and concluded that the validating accuracy is **83%** . \n",
        "\n",
        "which can further be increased by applying diffrent algorithm and using k fold technique in our dataset."
      ]
    }
  ]
}