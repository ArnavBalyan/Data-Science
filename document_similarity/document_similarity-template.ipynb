{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context-based similar documents problem can help us to find the similar documents of document which are necceesary. Many times, people do recommend the several items, which could be related to several data that customers read. Several techniques are there to find the similarity between the document but, in this project we will be using the concept of LDA and gensim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Several Steps involved in this Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project there several essential steps in order to complete this project.All the steps are lsited in following section.\n",
    "\n",
    "<h3> Data Preprocessing </h3>\n",
    "\n",
    "In data preprocessing, we need to make sure that our data is cleaned. in project like document similarity we do need to focus on the most occuring words in the document. for data preprocessing we need to make sure that our text is tokenised into sentences and words, and stop words should be removed. \n",
    "\n",
    "<h3> Data Modelling </h3>\n",
    "\n",
    "In data modelling , we need to build a model for our dataset. A data model wiill help us to find the most occuring words in the documents in the corpus. For creating a model one can make use of TF-IDF. \n",
    "For this project I have used LDA model. As it will indicate each topic with ists tuple. also the frequency of terms in each document would give signature of its uniqueness. \n",
    "\n",
    "<h3> Model testing</h3>\n",
    "\n",
    "in model testing we will apply the LDA algorithm to all the input documents and then with the use of several techniques we will calculate the similarity among the documents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libaries Used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Gensim\n",
    "<li>NLTK\n",
    "<li>Codecs\n",
    "<li>Pandas\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "import codecs\n",
    "from gensim import models, similarities\n",
    "import os\n",
    "import pickle\n",
    "import codecs\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the Structure of Dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "colnames=[\"id\",\"title\",\"content\"]\n",
    "inf = pandas.read_csv('articles1.csv',columns=colnames, nrows=10)\n",
    "data= inf.content.tolist()\n",
    "fileid=inf.id.tolist()\n",
    "ame=inf.title.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data contains 5000 entries and 10 columns. Following is the glimpse of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <td>month</td>\n",
       "      <td>url</td>\n",
       "      <td>content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <th>17283</th>\n",
       "      <th>House Republicans Fret About Winning Their Health Care Suit - The New York Times</th>\n",
       "      <th>New York Times</th>\n",
       "      <th>Carl Hulse</th>\n",
       "      <th>2016-12-31</th>\n",
       "      <th>2016.0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WASHINGTON  —   Congressional Republicans have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <th>17284</th>\n",
       "      <th>Rift Between Officers and Residents as Killings Persist in South Bronx - The New York Times</th>\n",
       "      <th>New York Times</th>\n",
       "      <th>Benjamin Mueller and Al Baker</th>\n",
       "      <th>2017-06-19</th>\n",
       "      <th>2017.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>After the bullet shells get counted, the blood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <th>17285</th>\n",
       "      <th>Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial Bias, Dies at 106 - The New York Times</th>\n",
       "      <th>New York Times</th>\n",
       "      <th>Margalit Fox</th>\n",
       "      <th>2017-01-06</th>\n",
       "      <th>2017.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When Walt Disney’s “Bambi” opened in 1942, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <th>17286</th>\n",
       "      <th>Among Deaths in 2016, a Heavy Toll in Pop Music - The New York Times</th>\n",
       "      <th>New York Times</th>\n",
       "      <th>William McDonald</th>\n",
       "      <th>2017-04-10</th>\n",
       "      <th>2017.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Death may be the great equalizer, but it isn’t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                id  \\\n",
       "NaN id    title                                              publication    author                        date       year    month   \n",
       "0.0 17283 House Republicans Fret About Winning Their Heal... New York Times Carl Hulse                    2016-12-31 2016.0   12.0   \n",
       "1.0 17284 Rift Between Officers and Residents as Killings... New York Times Benjamin Mueller and Al Baker 2017-06-19 2017.0    6.0   \n",
       "2.0 17285 Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial B... New York Times Margalit Fox                  2017-01-06 2017.0    1.0   \n",
       "3.0 17286 Among Deaths in 2016, a Heavy Toll in Pop Music... New York Times William McDonald              2017-04-10 2017.0    4.0   \n",
       "\n",
       "                                                                                                                            title  \\\n",
       "NaN id    title                                              publication    author                        date       year     url   \n",
       "0.0 17283 House Republicans Fret About Winning Their Heal... New York Times Carl Hulse                    2016-12-31 2016.0   NaN   \n",
       "1.0 17284 Rift Between Officers and Residents as Killings... New York Times Benjamin Mueller and Al Baker 2017-06-19 2017.0   NaN   \n",
       "2.0 17285 Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial B... New York Times Margalit Fox                  2017-01-06 2017.0   NaN   \n",
       "3.0 17286 Among Deaths in 2016, a Heavy Toll in Pop Music... New York Times William McDonald              2017-04-10 2017.0   NaN   \n",
       "\n",
       "                                                                                                                                                                       content  \n",
       "NaN id    title                                              publication    author                        date       year                                              content  \n",
       "0.0 17283 House Republicans Fret About Winning Their Heal... New York Times Carl Hulse                    2016-12-31 2016.0  WASHINGTON  —   Congressional Republicans have...  \n",
       "1.0 17284 Rift Between Officers and Residents as Killings... New York Times Benjamin Mueller and Al Baker 2017-06-19 2017.0  After the bullet shells get counted, the blood...  \n",
       "2.0 17285 Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial B... New York Times Margalit Fox                  2017-01-06 2017.0  When Walt Disney’s “Bambi” opened in 1942, cri...  \n",
       "3.0 17286 Among Deaths in 2016, a Heavy Toll in Pop Music... New York Times William McDonald              2017-04-10 2017.0  Death may be the great equalizer, but it isn’t...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is/are some useful features in the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our basic aim is to find any similar documents to our query. so for here in our dataset, there are four main coloumns, which are really neccessary for us to build our project. Four main coloums are id, title, content,url."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are Features in dataset, that will be neccessary to do investigation into the features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our main features would be \n",
    "ID\n",
    "Title\n",
    "Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A next step is to create a Bag of Words on the dataset. A dictionary would be created from all the processed documents. A dictionary will contain the number of times word appeared in the training set. You can use in built function dictionary for creating a dictionary  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_file=\"stopwords.txt\"\n",
    "stopwords=[]\n",
    "if stopwords_file is not None:\n",
    "    sreader = codecs.open(\"stopwords.txt\", 'r', 'utf8')\n",
    "    for line in sreader.readlines():\n",
    "        stopwords.append(line.replace('\\n', ''))\n",
    "stoplist = set(stopwords)\n",
    "sentences = [[word for word in content.split(u' ') if word not in stoplist] for content in data]\n",
    "\n",
    "dictionary=corpora.Dictionary(sentences)\n",
    "dictionary.save(\"dictionary.dict\")\n",
    "corpus=[dictionary.doc2bow(sentence) for sentence in sentences]\n",
    "corpora.MmCorpus.serialize(\"corpus.mm\",corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several steps are invloved in data preprocessing.\n",
    "\n",
    "Tokenization: in this step, we split all content of document into sentences and that into words.\n",
    "all the stop words are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using the data collected from the dataset, we will be preprocessing it and make, it more clean. since there are several documents, in each document, we need to tokenize it into sentences and words, also removing all the stop words. once the data is cleaned we will make a dictionary. and then finally a corpus. A corpus is the collection of the input document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=100)\n",
    "model.save(\"model.lda\")\n",
    "model = models.ldamodel.LdaModel.load(\"model.lda\")\n",
    "word_occurs=False\n",
    "high_frequency_words=15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is LDA Algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA or Latent Dirichlet Allocation is another topic model, and it does the classification of several douments according to their niche. LDA builds a document model, and model of words in each topic. All of this is modeled as the Direchlet Distributions. you can use LDA model to find the most common words used in the documents. Based on LDA algoirthm , you can rank the document and most common words used in each document.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "write your own code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "write your own code!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does Similarity class work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A main class is similarity, which is used to build the index of the collection of documents. once the index is build,we can check how similar is the query document to the all the vectors of numbers. \n",
    "\n",
    "Simailarity Class divides the index into several small sub indices. with the use of other functionalities, such as MatrixSimilary we can find the similarity between the documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim doc2bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have used the library Gensim Doc2bow, generally it creates a dectionary and it gives the number of words appeared.based on this we will get to know about the frequency of words used in several documents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to test a Model on Query?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write your own code! # for checking the query you need to create a doc2bow of the query document, which means that you need to clean the document and remove all the unneccessary words. based on that you need to fit it in the LDA document. and use similarity library for checking the document query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, the results are ways much better and quite accuarate. Such code can be used to build the recommendation system, like with the help of such data, we can recommend people about blogs and artiicles according their context they like to read."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
