{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping - LinkedIn Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinkedIn is a very rich source of content when it comes to employment or various types of opportunities. Today we will be scraping some data off LinkedIn based on some keywords or a particular hashtag.<br>\n",
    "Let's start with taking input the keywords or a hastag to search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an Evironment\n",
    "Importing the packages and libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, sys, time\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse\n",
    "from selenium import webdriver \n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since LinkedIn only allows a single hashtag search, take input for only one hashtag, if you want a hashtag based search. However we may search for multiple keywords, so take multiple inputs for a keyword based search in case a keyword based search is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take input for desired keyword/hashtag and store it into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start up the web-browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the login link from the browser\n",
    "# Enter the LinkedIn home page link to open the website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a config txt file, The first line of this file will be the LinkedIn username, second line will be the password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the username and password from config file\n",
    "# Read the file here and store the username and password from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the credentials to LinkedIn login page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the url\n",
    "This is done to search for the hashtag or keyword. After creating the url, send it to the browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Hashtag create something like this\n",
    "#link = 'https://www.linkedin.com/feed/hashtag/sample/'\n",
    "# For keywords, create something like this\n",
    "#link = 'https://www.linkedin.com/search/results/content/?keywords=research%2C%20intern'\n",
    "# Send the url to the browser after generating it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the url is entered, scroll to the required amount of page length to get maximum data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scroll down to some desired length of the page to get more than just the posts shown on the initial screen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinkedIn condenses its posts by showing a small preview. We must press on all the \"see more\" buttons to expand the content and reveal the full data of all posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search for the \"see more\" button's class and find elements by this class. \n",
    "#After doing this, click on all \"see more\" buttons of all the posts on the page. This will expose full content of all posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is ready to be scraped. We will use beautiful soup to extract the data and then, clean it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bs4 object and enter all the page source in this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start searching for the elements you need and clean the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for the data we need by its class name. Then  run a for loop to get the Name of the person who posted,their position and designation and content of the post. We also exctract the links, and take content of a post that is shared in another post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list and keep on appending the scraped data to this list.\n",
    "# Once this is done, data is ready to be saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Data\n",
    "As you can see, we have successfully extracted all the data and saved it into a list. Now organise it and save it into a csv file. Since data is scrapped at regular periods of interval to stay upto date with the content, save the csv name as the current timestamp to keep track of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web Scraping is an extremely powerful technique to get huge amounts of data in a couple of seconds. It acts as a great tool for Data Scientists and Analysis to get hold of data and process it for various applications. Pls note, scrapping data may not be legal for all websites, make sure that you read about the licenses and notices of a website before scraping off any data.\n",
    "Good Luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
