{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* * * *\n",
    "### 1. Introduction\n",
    "\n",
    "This dataset is a collection of images that are commonly used to train machine learning and computer vision algorithms. It is one of the most widely used datasets for machine learning research. The CIFAR-10 dataset contains 60,000 32x32 color images in 10 different classes. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class. In this competition, your goal is to correctly identify different object from a dataset of tens of thousands of color images.\n",
    "* * * *\n",
    "This notebook is divided in the following sections:\n",
    "1. Introduction\n",
    "1. Data preparation\n",
    "    1. Load data\n",
    "    1. Normalization, Reshape and Label encoding\n",
    "    1. Visualize test and train sample\n",
    "1. Model Building\n",
    "    1. Split training and valdiation set\n",
    "    1. Define the model architechture\n",
    "    1. Set the optimizer and annealer\n",
    "    1. Data augmentation\n",
    "    1. Train model\n",
    "1. Evaluate the model\n",
    "    1. Training and validation curves\n",
    "    1. Visualize Prediction\n",
    "1. Prediction and submition\n",
    "    1. Predict and Submit results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\Arnav\\Anaconda3\\envs\\gpu\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "# Importing relevant packages and modules\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from  os import listdir\n",
    "# import backend\n",
    "import tensorflow as tf\n",
    "# Model architecture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D\n",
    "from keras.layers import MaxPool2D, Activation, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "# Annealer\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# Data processing\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Progressor\n",
    "from tqdm import tqdm\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR10 Datset using keras\n",
    "# Usage Example:\n",
    "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Prepration\n",
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#Print the shape for test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check dimensions of the loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of classes in training and testing samples\n",
    "\n",
    "#Create a bar graph having ddistribution of all the classses to check for any imbalanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Next, we must do the following:*\n",
    "**Normalization, Reshape and Label Encoding**\n",
    "\n",
    "***Normalization***\n",
    "* Perform a grayscale normalization to reduce the effect of illumination's differences.\n",
    "* If we perform normalization, CNN works faster.\n",
    "***Reshape***\n",
    "* Train and test images (32 x 32)\n",
    "* Reshape all data to -1*28x28x1 4D matrices.\n",
    "\n",
    "***Label Encoding***\n",
    "* Encode labels to one hot vectors\n",
    "* Example:\n",
    "> 2 => [0,0,1,0,0,0,0,0,0,0] <br>\n",
    "> 4 => [0,0,0,0,1,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to reshape and scaling image\n",
    "# Create a function to reshape the images to (-1,32,32,3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Testing data processing\n",
    "# Call the function to reshape, scale images on training and testing data\n",
    "\n",
    "# Label processing\n",
    "# One hot encode the training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Use sklearn LabelEncoder to encode test labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize test and train sample**\n",
    "##### Train sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# visualizing training samples\n",
    "# Plot the first 40 training images on a 10 x 4 grid \n",
    "# This will help us to visualize the train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# visualizing test samples\n",
    "# Plot the first 40 test images on a 10 x 4 grid \n",
    "# This will help us to visualize the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Building: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split training and valdiation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training and validation set.\n",
    "# Use train_test_split to split the traing data into train and validation test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model architechture\n",
    "\n",
    "****\n",
    "\n",
    "**CNNs and their layers:**\n",
    "\n",
    "**Convolutional neural networks (CNNs)** are the current **state-of-the-art model architecture** for image classification tasks. CNNs apply a series of filters to the raw pixel data of an image to extract and learn higher-level features, which the model can then use for classification. CNNs contains different components:\n",
    "\n",
    "***Convolutional layers***, which apply a specified number of convolution filters to the image. For each subregion, the layer performs a set of mathematical operations to produce a single value in the output **feature map**. Convolutional layers then typically apply a **ReLU activation** function) to the output to introduce **nonlinearities** into the model.\n",
    "\n",
    "***BatchNormalization layers***, Batch Normalization is a technical trick to make training faster.\n",
    "\n",
    "***Dropout layers***, Dropout is a regularization method, where the layer randomly replaces a proportion of its weights to zero for each training sample. This forces the net to learn features in a distributed way, not relying to much on a particular weight, and therefore improves generalization.\n",
    "\n",
    "***Activation layers***, Activation functions are really important for a any Neural Network to learn and make sense of something really complicated and Non-linear complex functional mappings between the inputs and response variable.They introduce **non-linear properties** to our Network.\n",
    "\n",
    "***Pooling layers***, which downsample the image data extracted by the convolutional layers to reduce the dimensionality of the feature map in order to decrease processing time. A commonly used pooling algorithm is max pooling, which extracts subregions of the feature map (e.g., 2x2-pixel tiles), keeps their maximum value, and discards all other values. it gives **rotation invariant** feature extraction ability to model. \n",
    "\n",
    "***Dense (fully connected) layers***, which perform classification on the features extracted by the convolutional layers and downsampled by the pooling layers. In a dense layer, every node in the layer is connected to every node in the preceding layer.\n",
    "\n",
    "Typically, a CNN is composed of a stack of convolutional modules that perform feature extraction. Each module consists of a convolutional layer followed by a pooling layer. The last convolutional module is followed by one or more dense layers that perform classification. The final dense layer in a CNN contains a single node for each target class in the model (all the possible classes the model may predict), with a softmax activation function to generate a value between 0â€“1 for each node (the sum of all these softmax values is equal to 1). We can interpret the softmax values for a given image as relative measurements of how likely it is that the image falls into each target class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD CONVOLUTIONAL NEURAL NETWORKS\n",
    "# Build a CNN model\n",
    "# Compile this model\n",
    "# Print the model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the optimizer and annealer**\n",
    "\n",
    "We train once with a smaller learning rate to ensure convergence. We then speed things up, only to reduce the learning rate by 10% every epoch. Keras has a function for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "# learning rate schedule\n",
    "# Create a function to change learning rate for every epoch (This step is optional but ensures performance)\n",
    "\n",
    "# learning schedule callback\n",
    "# Use Keras LearningRateScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data augmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid overfitting problem, we need to expand artificially our dataset. We can make existing dataset even larger by altering the training data with small transformations.\n",
    "\n",
    "For the data augmentation, we can:\n",
    "\n",
    "* Randomly rotate some training images by 10 degrees\n",
    "* Randomly Zoom by 10% some training images\n",
    "* Randomly shift images horizontally by 10% of the width\n",
    "* Randomly shift images vertically by 10% of the height\n",
    "* Randomly flip images horizontally.\n",
    "\n",
    "Not: We cannot apply a vertical_flip since it could misclassify symetrical object like aeroplane and bird, truck and ships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augumetation\n",
    "# Perform Data augmentation using ImageDataGenerator\n",
    "# Data generator model to train and validation set\n",
    "# Set batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generated sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# visualizing augumented image\n",
    "# Print 10 augmented variants of an image in a row\n",
    "# Do this for 3 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traing parameters\n",
    "# Set epoch and Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model with the required parametes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the loss and accuracy of validation data for the fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate the model\n",
    "\n",
    "**Training and validation curves**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy curves for training and validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize Result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# making predictions\n",
    "# PREVIEW PREDICTIONS\n",
    "# Create a plot to visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prediction and submition\n",
    "**Predict and Submit results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on test\n",
    "# Now use the test data and save the predictions of test data in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the predicted numbers into labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save these predicted labels in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now classify images using CNNs which are a very powerful and handy when it comes to neural networks. Additionally, you may run this on other models/ classifiers and compare your results with CNNs. Ussually, Convolutional Neural Networks will outperform them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
