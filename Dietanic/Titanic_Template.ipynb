{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook,yo will use an open data set with data on the passengers aboard the infamous doomed sea voyage of 1912. By examining factors such as class, sex, and age, you will use machine learning algorithms and build a program that can predict whether a given passenger would have survived this disaster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMS Titanic was a British passenger liner that sank in the North Atlantic Ocean in the early morning hours of 15 April 1912, \n",
    "after it collided with an iceberg during its maiden voyage from Southampton to New York City. There were an estimated 2,224 \n",
    "passengers and crew aboard the ship, and more than 1,500 died, making it one of the deadliest commercial peacetime maritime \n",
    "disasters in modern history. The RMS Titanic was the largest ship afloat at the time it entered service and was the second of \n",
    "three Olympic-class ocean liners operated by the White Star Line. The Titanic was built by the Harland and Wolff shipyard in\n",
    "Belfast. Thomas Andrews, her architect, died in the disaster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all the necessary Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import numpy as np\n",
    "#import seaborn as sns\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the train and test set into Pandas Dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the shape of the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a code to check the shape of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the shape of the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a code to check the shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the Passenger Id of the test dataset separately as you will need it during the prediction stage.\n",
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Passenger Id as the index of both the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write code for train set here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write code for test set here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for the null values in both train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write code for train set here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write code for test set here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the data type of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using missingno library visualize the NaN values in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import missingno as mn\n",
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Imputer class to deal with 'Age' Column missing values in the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For train set\n",
    "#from sklearn.preprocessing import Imputer\n",
    "#Write your code here\n",
    "#Write your code here\n",
    "#Write your code here\n",
    "#Write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For test set\n",
    "#from sklearn.preprocessing import Imputer\n",
    "#Write your code here\n",
    "#Write your code here\n",
    "#Write your code here\n",
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for null values again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill the missing values in the 'Embarked' Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here\n",
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the String into an Integer in the 'Embarked' Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n",
    "#Write your code here\n",
    "#Write your code here\n",
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with the missing values in the 'Fare' Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping the 'Age' and  'Cabin' Columns in both train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here\n",
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the 'Sex' Column into an integer using .apply() method in both train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For train set\n",
    "#Write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For test set\n",
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A convenient definition of an outlier is a point which falls more than 1.5 times the interquartile range above the third quartile or below the first quartile. Outliers can also occur when comparing relationships between two sets of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A value that \"lies outside\" (is much smaller or larger than) most of the other values in a set of data. For example in the scores 25,29,3,32,85,33,27,28 both 3 and 85 are \"outliers\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the boxplot approach to detect the outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A boxplot is a graph that gives you a good indication of how the values in the data are spread out. Although boxplots may seem primitive in comparison to a histogram or density plot, they have the advantage of taking up less space, which is useful when comparing distributions between many groups or datasets. Boxplots are a standardized way of displaying the distribution of data based on a five number summary (“minimum”, first quartile (Q1), median, third quartile (Q3), and “maximum”)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median (Q2/50th Percentile): The middle value of the dataset.\n",
    "### First quartile (Q1/25th Percentile): The middle number between the smallest number (not the “minimum”) and the median of the dataset.\n",
    "### Third quartile (Q3/75th Percentile): The middle value between the median and the highest value (not the “maximum”) of the dataset.\n",
    "### Interquartile range (IQR): 25th to the 75th percentile.\n",
    "### Whiskers: The data points lying between the 25th Percentile and the smallest number(not the \"minimum\") and the data points lying between the 75th Percentile and the largest number(not the \"maximum\")\n",
    "### Outliers: Lying outside most of the other values in a set of data\n",
    "### Maximum: Q3 + 1.5*IQR\n",
    "### Minimum: Q1 -1.5*IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.boxplot(x='Survived',y='Fare',data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As you can see there are outliers present and hence you should remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the overall chance of survival for a Titanic Passenger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Survival Rate using Pie Diagram and find out what % of the passengers survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with the Age first-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['Age2'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['Age2'].describe().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which age group survived the most?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby Age:\n",
    "Cut the Age Column of the train data set with range from 10 to 90 and an interval of 10 and then plot a bar graph to analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group_by_age = pd.cut(train[\"Age2\"], np.arange(0, 90, 10))\n",
    "#Write your code here\n",
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What fare range had a higher chance of survival?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Groupby Fare:\n",
    "Do the same process you did for Age column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group_by_fare = pd.cut(train[\"Fare\"], np.arange(0, 300, 50))\n",
    "#Write your code here\n",
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  What Class had a lucky escape?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby Class:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group everything by class and plot a bar graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_grouping=train.groupby('Pclass').mean()\n",
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which Gender had a higher chance of survival?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.barplot(x='Sex',y='Survived',data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bivariate Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which gender across every class had a higher chance of survival?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Groupby Sex and Class:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group everything by sex and class and plot a bar graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sex_class_grouping=train.groupby(['Pclass','Sex']).mean()\n",
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the Siblings and Spouses with Parents and Children."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby SibSp and Parch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group everything by Sibsp and Parch and plot a bar graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sib_par_group=train.groupby(['SibSp','Parch']).mean()\n",
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the correlations between the features using Heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a heatmap?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each square shows the correlation between the variables on each axis. Correlation ranges from -1 to +1. Values closer to zero means there is no linear trend between the two variables. The close to 1 the correlation is the more positively correlated they are; that is as one increases so does the other and the closer to 1 the stronger this relationship is. A correlation closer to -1 is similar, but instead of both increasing one variable will decrease as the other increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagonals are all 1/dark green because those squares are correlating each variable to itself (so it's a perfect correlation). For the rest the larger the number and darker the color the higher the correlation between the two variables. The plot is also symmetrical about the diagonal since the same two variables are being paired together in those squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.subplots(figsize=(15,8))\n",
    "#sns.heatmap(train.corr(),annot=True,cmap='PiYG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the Posititve Correlation features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the Negative Correlation features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the total number of people in the family? Create a new column for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[\"family_size\"]=train['SibSp']+train['Parch']+1\n",
    "#train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a function to understand the family size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def family_group(size):\n",
    "    #a=''\n",
    "    \n",
    "    #if(size<=1):\n",
    "        #a='alone'\n",
    "        \n",
    "    #elif(size<=4):\n",
    "        #a='small'\n",
    "        \n",
    "    #else:\n",
    "        #a='large'\n",
    "        \n",
    "    #return a\n",
    "\n",
    "#train[\"family_group\"]=train[\"family_size\"].map(family_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The map function will map the family_group function to the family size and accordingly you will have an idea about the size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat the same process for the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using function to have an idea about the Age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def age_group(age):\n",
    "    #a=''\n",
    "    \n",
    "    #if(age<=1):\n",
    "        #a='infant'\n",
    "        \n",
    "    #elif(age<=4):\n",
    "        #a='toddler'\n",
    "        \n",
    "    #elif(age<=14):\n",
    "        #a='child'\n",
    "        \n",
    "    #elif(age<=15):\n",
    "        #a='teenager'\n",
    "        \n",
    "    #elif(age<=25):\n",
    "        #a='young_adult'\n",
    "        \n",
    "    #elif(age<=40):\n",
    "        #a='adult'\n",
    "        \n",
    "    #elif(age<=55):\n",
    "        #a='middle_age'\n",
    "        \n",
    "    #else:\n",
    "        #a='old'\n",
    "        \n",
    "    #return a\n",
    "    \n",
    "    \n",
    "#train[\"age_group\"]=train[\"Age2\"].map(age_group)\n",
    "#train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat the same process for the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the fare per person?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the fare by \"Fare\" by \"family_size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a function to get an idea about the fare paid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def fare_group(Fare):\n",
    "    #a=''\n",
    "    \n",
    "    #if(Fare<=4):\n",
    "        #a='very_low'\n",
    "        \n",
    "    #elif(Fare<=10):\n",
    "        #a='low'\n",
    "        \n",
    "    #elif(Fare<=20):\n",
    "        #a='mid'\n",
    "        \n",
    "    #elif(Fare<=45):\n",
    "        #a='high'\n",
    "        \n",
    "    #else:\n",
    "        #a='very_high'\n",
    "        \n",
    "    #return a\n",
    "\n",
    "#train[\"fare_group\"]=train[\"fare_per_person\"].map(fare_group)\n",
    "#train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat the same process for test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the unessential columns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out which columns won't contribute in predicting the survival and drop them accordingly in both train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For train set\n",
    "#Write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For test set\n",
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import StratifiedShuffleSplit,train_test_split\n",
    "#from sklearn.metrics import accuracy_score,log_loss\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn import svm\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Machine Learning Algorithms to predict the survival:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest, like its name implies, consists of a large number of individual decision trees that operate as an ensemble. Each individual tree in the random forest spits out a class prediction and the class with the most votes becomes our model’s prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_forest = RandomForestClassifier(n_estimators=100)\n",
    "#random_forest.fit(X_train, y_train)\n",
    "\n",
    "#y_prediction = random_forest.predict(X_test)\n",
    "\n",
    "#random_forest.score(X_train, y_train)\n",
    "#acc_random_forest = round(random_forest.score(X_train, y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is a Machine Learning classification algorithm that is used to predict the probability of a categorical dependent variable. In logistic regression, the dependent variable is a binary variable that contains data coded as 1 (yes, success, etc.) or 0 (no, failure, etc.). In other words, the logistic regression model predicts P(Y=1) as a function of X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logreg = LogisticRegression()\n",
    "#logreg.fit(X_train, y_train)\n",
    "\n",
    "#y_pred = logreg.predict(X_test)\n",
    "\n",
    "#acc_log = round(logreg.score(X_train, y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Baiyes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do you know how it works?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the Bayes Theorem first-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes’ Theorem finds the probability of an event occurring given the probability of another event that has already occurred. Bayes’ theorem is stated mathematically as the following equation:\n",
    "\n",
    " **P(A|B) = {P(B|A) P(A)}/{P(B)}** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primarily Naïve Bayes is a linear classifier, which is a supervised machine learning method and works as a probabilistic classifier as well.  When handling real-time data with continuous distribution, Naïve Bayes classifier considers that the big data is generated through a Gaussian process with normal distribution. \n",
    "\n",
    "In Gaussian Naive Bayes, continuous values associated with each feature are assumed to be distributed according to a Gaussian distribution. A Gaussian distribution is also called Normal distribution. When plotted, it gives a bell shaped curve which is symmetric about the mean of the feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaussian = GaussianNB() \n",
    "#gaussian.fit(X_train, y_train)\n",
    "#y_pred = gaussian.predict(X_test)\n",
    "#acc_gaussian = round(gaussian.score(X_train, y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Knn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN can be used for classification — the output is a class membership (predicts a class — a discrete value). An object is classified by a majority vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "#knn.fit(X_train, y_train)  \n",
    "#y_pred = knn.predict(X_test)  \n",
    "#acc_knn = round(knn.score(X_train, y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting to know the Decision Tree Classifiers-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree is the most powerful and popular tool for classification and prediction. A Decision tree is a flowchart like tree structure, where each internal node denotes a test on an attribute, each branch represents an outcome of the test, and each leaf node (terminal node) holds a class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision_tree = DecisionTreeClassifier()\n",
    "#decision_tree.fit(X_train, y_train)\n",
    "#y_pred = decision_tree.predict(X_test) \n",
    "#acc_decision_tree = round(decision_tree.score(X_train, y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Support Vector Machine:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Support Vector Machine (SVM) is a discriminative classifier formally defined by a separating hyperplane. In other words, given labeled training data (supervised learning), the algorithm outputs an optimal hyperplane which categorizes new examples.\n",
    "\n",
    "An SVM model is a representation of the examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible.\n",
    "In addition to performing linear classification, SVMs can efficiently perform a non-linear classification, implicitly mapping their inputs into high-dimensional feature spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.svm import SVC, LinearSVC\n",
    "#linear_svc = LinearSVC()\n",
    "#linear_svc.fit(X_train, y_train)\n",
    "\n",
    "#y_pred = linear_svc.predict(X_test)\n",
    "\n",
    "#acc_linear_svc = round(linear_svc.score(X_train, y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which is the Best Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are so many Algorithms, it is really difficult to choose the one for predicting the final data. So you need to compare your models and choose the one with the highest accuracy.\n",
    "\n",
    "Using the sklearn library you can find out the scores of your ML Model and thus choose the algorithm with a higher score to predict your output. Another good way is to calculate errors such as mean absolute error and mean squared error and try to minimize them to better our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes',  \n",
    "              'Decision Tree'],\n",
    "    'Score': [acc_linear_svc, acc_knn, acc_log, \n",
    "              acc_random_forest, acc_gaussian,  \n",
    "              acc_decision_tree]})\n",
    "result_df = results.sort_values(by='Score', ascending=False)\n",
    "result_df = result_df.set_index('Score')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How will you assure yourself with the best model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, you couldn’t fit the model on the training data and can’t say that the model will work accurately for the real data. For this, you must assure that your model got the correct patterns from the data, and it is not getting up too much noise. For this purpose, you use the cross-validation technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Cross Validation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is a technique in which we train our model using the subset of the data-set and then evaluate using the complementary subset of the data-set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three steps involved in cross-validation are as follows :\n",
    "\n",
    "1. Reserve some portion of sample data-set.\n",
    "2. Using the rest data-set train the model.\n",
    "3. Test the model using the reserve portion of the data-set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform K Fold Cross Validation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this method, you split the data-set into k number of subsets(known as folds) then you perform training on the all the subsets but leave one(k-1) subset for the evaluation of the trained model. In this method, you iterate k times with a different subset reserved for testing purpose each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import cross_val_score\n",
    "#rf = RandomForestClassifier(n_estimators=100)\n",
    "#scores = cross_val_score(rf, X_train, y_train, cv=10, scoring = \"accuracy\")\n",
    "#print(\"Scores:\", scores)\n",
    "#print(\"Mean:\", scores.mean())\n",
    "#print(\"Standard Deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the most important features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the most import features and plot a bar graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(random_forest.feature_importances_,3)})\n",
    "#importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
    "#importances.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Random Forest Again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_forest = RandomForestClassifier(n_estimators=100, oob_score = True)\n",
    "#random_forest.fit(X_train, y_train)\n",
    "#y_prediction = random_forest.predict(X_test)\n",
    "\n",
    "#random_forest.score(X_train, y_train)\n",
    "\n",
    "#acc_random_forest = round(random_forest.score(X_train, y_train) * 100, 2)\n",
    "#print(round(acc_random_forest,2,), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the results of the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the Array into Dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output = pd.DataFrame({ 'PassengerId' : passenger_id, 'Survived': y_prediction })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
